
> # In essence, hypertuning is done through flags. Anywhere in your neural network, 
> # you can replace a parameter with a flag
> FLAGS <- flags(
+   .... [TRUNCATED] 

> #
> 
> # build the neural network
> five.layer.model <- function() {
+   model <- keras_model_sequential() 
+   model %>%
+     layer_dense(units =  .... [TRUNCATED] 

> layer5_model <- five.layer.model()

> layer5_model %>% summary()
Model: "sequential"
____________________________________________________________________________________________________
Layer (type)                                 Output Shape                            Param #        
====================================================================================================
dense_5 (Dense)                              (None, 128)                             13184          
____________________________________________________________________________________________________
dropout_4 (Dropout)                          (None, 128)                             0              
____________________________________________________________________________________________________
dense_4 (Dense)                              (None, 16)                              2064           
____________________________________________________________________________________________________
dropout_3 (Dropout)                          (None, 16)                              0              
____________________________________________________________________________________________________
dense_3 (Dense)                              (None, 16)                              272            
____________________________________________________________________________________________________
dropout_2 (Dropout)                          (None, 16)                              0              
____________________________________________________________________________________________________
dense_2 (Dense)                              (None, 8)                               136            
____________________________________________________________________________________________________
dropout_1 (Dropout)                          (None, 8)                               0              
____________________________________________________________________________________________________
dense_1 (Dense)                              (None, 128)                             1152           
____________________________________________________________________________________________________
dropout (Dropout)                            (None, 128)                             0              
____________________________________________________________________________________________________
dense (Dense)                                (None, 1)                               129            
====================================================================================================
Total params: 16,937
Trainable params: 16,937
Non-trainable params: 0
____________________________________________________________________________________________________

> # define early stop monitor
> early_stop <- callback_early_stopping(monitor = "val_loss", patience = 20)

> # define the number of epochs
> epochs <- 150

> # Fit the model and store training stats
> history <- layer5_model %>%
+   fit(x_train, y_train, epochs = epochs, batch_size = 128,
+       validati .... [TRUNCATED] 
